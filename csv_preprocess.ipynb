{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2173fd41",
   "metadata": {},
   "source": [
    "# Konfigurasi Awal\n",
    "Bagian konfigurasi awal untuk mendapatkan file input,\n",
    "## Download from google cloud storage\n",
    "Semua file input maupun output disimpan di cloud storage\n",
    "### Nama file\n",
    "file input: data/input-latest.csv\n",
    "file output: data/output-latest.json\n",
    "> Boleh juga jika modelnya ingin diexport\n",
    "#### File input dikoleksi setiap hari dengan format input-timestamp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "os.environ[\"TFVERSION\"] = \"2.5\"\n",
    "os.environ[\"PYTHONVERSION\"] = \"3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p data\n",
    "gsutil -q -m cp gs://$BUCKET_NAME/data/input* data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputList = sorted(glob.glob('data/input-1*.csv'))\n",
    "print(inputList)\n",
    "isOk = glob.glob('data/input-aafsa.csv')\n",
    "not inputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597deed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_add_date(path, isNeedParse=True):\n",
    "    csvData = pd.read_csv(path)\n",
    "    if isNeedParse:\n",
    "        csvData[\"date\"] = pd.to_datetime(\n",
    "            datetime.fromtimestamp(\n",
    "                int(path.split(\"-\")[-1][:-4])//1000\n",
    "            ))\n",
    "    return csvData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_merge():\n",
    "    isMergedDatasetExist = glob.glob('data/input-preprocessed.csv')\n",
    "    listOfDatasets = sorted(glob.glob('data/input-1*.csv'))\n",
    "    if not isMergedDatasetExist:\n",
    "        df_merge = pd.DataFrame()\n",
    "        for i, dataset in enumerate(listOfDatasets[:-1]):\n",
    "            df1 = read_csv_add_date(listOfDatasets[i])\n",
    "            df2 = read_csv_add_date(listOfDatasets[i+1])\n",
    "            df2[\"visitor\"] = df2[\"visitor\"].sub(df1[\"visitor\"])\n",
    "            if (i == 0):\n",
    "                df_merge = df_merge.append(df1, ignore_index = True)\n",
    "            df_merge = df_merge.append(df2, ignore_index = True)\n",
    "            df_merge.head(10);\n",
    "            \n",
    "        df_merge = df_merge.sort_values(\n",
    "            [\"id\", \"date\"], ascending = (True, True))\n",
    "        df_merge[\"date\"] = pd.to_datetime(\n",
    "            df_merge.date).dt.strftime(\"%-d/%-m/%Y %-H:%M\")\n",
    "        \n",
    "        df_merge.to_csv(\"data/input-preprocessed.csv\", index=False)\n",
    "#         display(df_merge.head())\n",
    "        \n",
    "    else:\n",
    "        df_merge = read_csv_add_date('data/input-preprocessed.csv', isNeedParse=False)\n",
    "        df_merge[\"date\"] = pd.to_datetime(\n",
    "            df_merge.date)\n",
    "        \n",
    "        df_to_merge = read_csv_add_date(\n",
    "            listOfDatasets[-1]) # read previous cumulative dump\n",
    "        df_to_sub = read_csv_add_date(\n",
    "            listOfDatasets[-2]) # read previous 2 cumulative dump\n",
    "        \n",
    "        df_to_merge[\"visitor\"] = df_to_merge[\"visitor\"].sub(df_to_sub[\"visitor\"]) # get non-cumulative visitor sum\n",
    "        \n",
    "        df_merge = df_merge.append(\n",
    "            df_to_merge, ignore_index = True)\n",
    "        df_merge = df_merge.sort_values(\n",
    "            [\"id\", \"date\"], ascending = (True, True))\n",
    "        \n",
    "        df_merge[\"date\"] = pd.to_datetime(\n",
    "            df_merge.date).dt.strftime(\"%-d/%-m/%Y %-H:%M\")\n",
    "        df_merge.to_csv(\"data/input-preprocessed.csv\", index=False)\n",
    "#         display(df_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce851ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83100ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDatasets = sorted(glob.glob('data/input-1*.csv'))\n",
    "display(listOfDatasets)\n",
    "display(listOfDatasets[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92697593",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merge)\n",
    "df_merge = df_merge.sort_values([\"id\", \"date\"], ascending = (True, False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv(\"data/input-raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237fbca",
   "metadata": {},
   "source": [
    "### Upload file output\n",
    "File output diupload ke cloud storage\n",
    "\n",
    "#### Format file output: \n",
    "`output-latest.json` dan `output-[timestamp].json`, boleh juga kalau mau upload bentuk lainnya (misal HDF5 nya dll.)\n",
    "> Pastikan output **disimpan ke direktori data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4af9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "gsutil cp data/output* gs://$BUCKET_NAME/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9da4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m70",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m70"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
